{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import sys\n",
    "from pathlib import Path  \n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from diffusers import DDIMScheduler\n",
    "import random\n",
    "project_root = Path.cwd().parent  \n",
    "# sys.path.append(str(project_root))\n",
    "os.chdir(project_root)\n",
    "from src.demo.model import FreeFinePipeline\n",
    "from src.utils.attention import (\n",
    "    Attention_Modulator,\n",
    "    register_attention_control_4bggen\n",
    ")\n",
    "from src.utils.vis_utils import temp_view,temp_view_img,load_json,get_constrain_areas,prepare_mask_pool,re_edit_2d,dilate_mask,read_and_resize_mask,read_and_resize_img\n",
    "\n",
    "\"\"\"\n",
    "Load FreeFine\n",
    "\"\"\"\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "pretrained_model_path = \"/data/Hszhu/prompt-to-prompt/stable-diffusion-v1-5/\" #Replace with your own ckpt path\n",
    "model = FreeFinePipeline.from_pretrained(pretrained_model_path, torch_dtype=torch.float16).to(device)\n",
    "model.scheduler = DDIMScheduler.from_config(model.scheduler.config,)\n",
    "controller = Attention_Modulator()\n",
    "model.controller = controller\n",
    "register_attention_control_4bggen(model, controller)\n",
    "model.modify_unet_forward()\n",
    "model.enable_attention_slicing()\n",
    "model.enable_xformers_memory_efficient_attention()\n"
   ],
   "id": "be098216c32bd9ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Case selection \n",
    "\"\"\"\n",
    "choice_dict = {\n",
    "    '0':['Examples/Removal/airplane/source.png','Examples/Removal/airplane/mask.png','empty snowfield scene'],\n",
    "    '1':['Examples/Removal/rhino/source.png','Examples/Removal/rhino/mask.png','empty forest scene'],\n",
    "    '2':['Examples/Removal/cat/source.png','Examples/Removal/cat/mask.png','empty wall scene'],\n",
    "    '3':['Examples/Removal/man/source.png','Examples/Removal/man/mask.png','empty modern street scene'],\n",
    "    '4':['Examples/Removal/woman/source.png','Examples/Removal/woman/mask.png','empty street scene'],\n",
    "}\n",
    "# sample_id = '0'\n",
    "sample_id = random.choice(list(choice_dict.keys()))\n",
    "ori_img_path,ori_mask_path,prompt = choice_dict[sample_id]\n",
    "ori_img_path =\"/data/zkl/geovis/rotate_supply/139/source.png\"\n",
    "ori_mask_path = \"/data/zkl/geovis/rotate_supply/139/s_mask.png\"\n",
    "prompt = 'wall'\n",
    "\n",
    "ori_img = read_and_resize_img(ori_img_path)\n",
    "ori_mask = read_and_resize_mask(ori_mask_path)\n",
    "mask_pool = [ori_mask] #add more object mask if you have, to avoid inpainting on them\n",
    "constrain_areas = get_constrain_areas(mask_list=mask_pool,ori_mask=ori_mask)\n",
    "dilation_factor = 20\n",
    "dil_ori_mask = dilate_mask(ori_mask, dilation_factor)\n",
    "dil_ori_mask = np.where(constrain_areas,0,dil_ori_mask)\n",
    "Image.fromarray(dil_ori_mask).save('obj_remove_mask.png')\n",
    "temp_view_img(ori_img,'ori_img')\n",
    "temp_view(dil_ori_mask,'dil_ori_mask')\n",
    "\n"
   ],
   "id": "9aa31dc560791565",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "seed_r = random.randint(0, 10 ** 16)\n",
    "# seed_r = 42\n",
    "generated_results = model.FreeFine_background_generation(ori_img, dil_ori_mask, prompt,\n",
    "                                                         guidance_scale=3.5,eta=1.0, end_step=50,\n",
    "                                                         num_step=50, end_scale=0.5,\n",
    "                                                         start_step=1, share_attn=True, method_type='tca',\n",
    "                                                         local_text_edit=True,\n",
    "                                                         local_perturbation=True, verbose=True,\n",
    "                                                         seed=seed_r,\n",
    "                                                         return_intermediates=False,latent_blended=False,\n",
    "                                                         )  \n",
    "temp_view_img(generated_results,'bg_img')\n",
    "save_img = Image.fromarray(generated_results)\n",
    "save_img.save(\"bg_img.png\")"
   ],
   "id": "dda48dcfe15f1fd6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
