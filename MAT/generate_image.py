# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
#
# NVIDIA CORPORATION and its licensors retain all intellectual property
# and proprietary rights in and to this software, related documentation
# and any modifications thereto.  Any use, reproduction, disclosure or
# distribution of this software and related documentation without an express
# license agreement from NVIDIA CORPORATION is strictly prohibited.

"""Generate images using pretrained network pickle."""
import cv2
import pyspng
import json
import time
import glob
import os
# os.environ["CUDA_VISIBLE_DEVICES"] = "5"
import re
import random
from typing import List, Optional
import matplotlib.pyplot as plt
from PIL import Image
import click
import dnnlib
import numpy as np
import PIL.Image
import torch
import torch.nn.functional as F

import legacy
# from datasets.mask_generator_512 import RandomMask
from networks.mat import Generator
from safetensors.torch import load_file



def temp_view_img(image, title: str = None) -> None:
    # PIL -> ndarray OR ndarray->PIL->ndarray
    if not isinstance(image, Image.Image):  # ndarray
        # image_array = Image.fromarray(image).convert('RGB')
        image_array = image
    else:  # PIL
        if image.mode != 'RGB':
            image.convert('RGB')
        image_array = np.array(image)

    plt.imshow(image_array)
    if title is not None:
        plt.title(title)
    plt.axis('off')  # Hide the axis
    plt.show()
def visualize_results(init_image, mask_image, output_image, caption):
    """
    Visualize the input image, mask, and output image in a single row.

    Args:
        init_image (PIL.Image): Original input image.
        mask_image (PIL.Image): Mask image used for editing.
        output_image (PIL.Image): Output image generated by BrushNet.
        caption (str): Text prompt used for generation.
    """
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))

    # Convert images to NumPy arrays for display
    init_image_np = np.array(init_image)
    mask_image_np = np.array(mask_image)
    output_image_np = np.array(output_image)

    # Display original image
    axes[0].imshow(init_image_np)
    axes[0].axis("off")
    axes[0].set_title("Original Image")

    # Display mask image
    axes[1].imshow(mask_image_np)
    axes[1].axis("off")
    axes[1].set_title("Mask Image")

    # Display output image
    axes[2].imshow(output_image_np)
    axes[2].axis("off")
    axes[2].set_title("MAT Output")

    # Add a main title for the figure
    plt.suptitle(caption, fontsize=16)
    plt.tight_layout()
    plt.show()
def visualize_results_pre(init_image, mask_image):
    """
    Visualize the input image and mask image in a single row.

    Args:
        init_image (PIL.Image): Original input image.
        mask_image (PIL.Image): Mask image used for editing.
    """
    # 清除所有先前的图像缓存
    plt.close('all')

    # 获取图像尺寸
    init_image_np = np.array(init_image)
    mask_image_np = np.array(mask_image)
    h, w, _ = init_image_np.shape  # 获取高度和宽度

    # 根据图像尺寸调整画布大小，保持宽高比例
    aspect_ratio = w / h
    fig, axes = plt.subplots(1, 2, figsize=(aspect_ratio * 6, 6))

    # 显示初始图像
    axes[0].imshow(init_image_np)
    axes[0].axis("off")
    axes[0].set_title("Original Image")

    # 显示掩码图像
    axes[1].imshow(mask_image_np)
    axes[1].axis("off")
    axes[1].set_title("Mask Image")

    # 调整布局并显示
    plt.tight_layout()
    plt.show()
def num_range(s: str) -> List[int]:
    '''Accept either a comma separated list of numbers 'a,b,c' or a range 'a-c' and return as a list of ints.'''

    range_re = re.compile(r'^(\d+)-(\d+)$')
    m = range_re.match(s)
    if m:
        return list(range(int(m.group(1)), int(m.group(2))+1))
    vals = s.split(',')
    return [int(x) for x in vals]

def copy_params_and_buffers(src_module, dst_module, require_all=False):
    assert isinstance(src_module, torch.nn.Module)
    assert isinstance(dst_module, torch.nn.Module)
    src_tensors = {name: tensor for name, tensor in named_params_and_buffers(src_module)}
    for name, tensor in named_params_and_buffers(dst_module):
        assert (name in src_tensors) or (not require_all)
        if name in src_tensors:
            tensor.copy_(src_tensors[name].detach()).requires_grad_(tensor.requires_grad)


def params_and_buffers(module):
    assert isinstance(module, torch.nn.Module)
    return list(module.parameters()) + list(module.buffers())


def named_params_and_buffers(module):
    assert isinstance(module, torch.nn.Module)
    return list(module.named_parameters()) + list(module.named_buffers())

def create_and_load_mat_model(network_pkl="/data/Hszhu/prompt-to-prompt/MAT/Places_512_FullData.pkl",device=None):
    with dnnlib.util.open_url(network_pkl) as f:
        G_saved = legacy.load_network_pkl(f)['G_ema'].to(device).eval().requires_grad_(False)  # type: ignore
    net_res = 512
    G = Generator(z_dim=512, c_dim=0, w_dim=512, img_resolution=net_res, img_channels=3).to(
        device).eval().requires_grad_(False)
    copy_params_and_buffers(G_saved, G, require_all=True)
    return G

def mat_forward(G,image_path,mask_path,resolution=512,do_dilation=True,dilation_factor=30,truncation_psi=1,device=None):
    # no Labels.
    label = torch.zeros([1, G.c_dim], device=device)
    def dilate_mask(mask, dilate_factor=15):
        mask = mask.astype(np.uint8)
        mask = cv2.dilate(
            mask,
            np.ones((dilate_factor, dilate_factor), np.uint8),
            iterations=1
        )
        return mask

    def read_image(image_path):
        with open(image_path, 'rb') as f:
            if pyspng is not None and image_path.endswith('.png'):
                image = pyspng.load(f.read())
            else:
                image = np.array(PIL.Image.open(f))
        if image.ndim == 2:
            image = image[:, :, np.newaxis]  # HW => HWC
            image = np.repeat(image, 3, axis=2)
        image = image.transpose(2, 0, 1)  # HWC => CHW
        image = image[:3]
        return image

    if resolution != 512:
        noise_mode = 'random'
    else:
        noise_mode = 'const'
    with torch.no_grad():
        image = read_image(image_path)
        mask = cv2.resize(cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE).astype(np.float32), image.shape[1:]) / 255.0
        image = (torch.from_numpy(image).float().to(device) / 127.5 - 1).unsqueeze(0)
        if do_dilation:
            dil_mask = dilate_mask(mask, dilation_factor)
        else:
            dil_mask = mask
        mask = 1 - dil_mask
        mask = torch.from_numpy(mask).float().to(device).unsqueeze(0).unsqueeze(0)

        z = torch.from_numpy(np.random.randn(1, G.z_dim)).to(device)
        output = G(image, mask, z, label, truncation_psi=truncation_psi, noise_mode=noise_mode)
        output = (output.permute(0, 2, 3, 1) * 127.5 + 127.5).round().clamp(0, 255).to(torch.uint8)
        output = output[0].cpu().numpy()
        return output,dil_mask

if __name__ == "__main__":
    """
      Generate images using pretrained network pickle.
      """
    network_pkl = "/data/Hszhu/prompt-to-prompt/MAT/Places_512_FullData.pkl"
    json_path = "/data/Hszhu/dataset/Subjects200K/Subset_4/mask_tag_relabelled_lmm_4.json"
    data = json.load(open(json_path, 'r', encoding='utf-8'))
    # actor_data = [d for d in  data if 'actor' in d['edit_prompt']]
    random.seed(time.time())
    key_list = list(data.keys())
    idx = random.randint(0, len(data) - 1)
    # random_image_data = data[key_list[idx]]
    random_image_data = data['15156']
    image_path = random_image_data['src_img_path']
    image_o = Image.open(image_path)
    ins = random_image_data['instances']
    level_instance = ins[0]
    mask_paths = level_instance['mask_path']
    obj_label = level_instance['obj_label']

    ins_idx = 0
    mask_path = mask_paths[ins_idx]
    image_m = Image.open(mask_path).convert("RGB")
    truncation_psi = 1
    noise_mode = 'const'
    resolution = 512
    # seed = 240  # pick up a random number
    seed = np.random.randint(0, 2 ** 32 - 1)
    random.seed(seed)
    print(f'seed is set to {seed}')
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)

    device = torch.device('cuda')



    with dnnlib.util.open_url(network_pkl) as f:
        G_saved = legacy.load_network_pkl(f)['G_ema'].to(device).eval().requires_grad_(False)  # type: ignore
    net_res = 512 if resolution > 512 else resolution
    G = Generator(z_dim=512, c_dim=0, w_dim=512, img_resolution=net_res, img_channels=3).to(
        device).eval().requires_grad_(False)
    copy_params_and_buffers(G_saved, G, require_all=True)


    # no Labels.
    label = torch.zeros([1, G.c_dim], device=device)
    def save_mask(mask, dst_path):
        cv2.imwrite(dst_path, mask)  # 将mask保存为png图片 (注意：mask是二值图，乘以255以得到可见的结果)

    def save_img(img, dst_path):
        cv2.imwrite(dst_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))
    def dilate_mask( mask, dilate_factor=15):
        mask = mask.astype(np.uint8)
        mask = cv2.dilate(
            mask,
            np.ones((dilate_factor, dilate_factor), np.uint8),
            iterations=1
        )
        return mask

    def read_image(image_path):
        with open(image_path, 'rb') as f:
            if pyspng is not None and image_path.endswith('.png'):
                image = pyspng.load(f.read())
            else:
                image = np.array(PIL.Image.open(f))
        if image.ndim == 2:
            image = image[:, :, np.newaxis]  # HW => HWC
            image = np.repeat(image, 3, axis=2)
        image = image.transpose(2, 0, 1)  # HWC => CHW
        image = image[:3]
        return image


    def to_image(image, lo, hi):
        image = np.asarray(image, dtype=np.float32)
        image = (image - lo) * (255 / (hi - lo))
        image = np.rint(image).clip(0, 255).astype(np.uint8)
        image = np.transpose(image, (1, 2, 0))
        if image.shape[2] == 1:
            image = np.repeat(image, 3, axis=2)
        return image


    if resolution != 512:
        noise_mode = 'random'
    with torch.no_grad():

        image = read_image(image_path)
        mask = cv2.resize(cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE).astype(np.float32), image.shape[1:]) / 255.0
        image = (torch.from_numpy(image).float().to(device) / 127.5 - 1).unsqueeze(0)


        dil_mask = dilate_mask(mask,30)
        vis_mask = np.expand_dims(dil_mask, axis=2).repeat(3, axis=2)*255
        mask = 1 - dil_mask
        mask = torch.from_numpy(mask).float().to(device).unsqueeze(0).unsqueeze(0)


        z = torch.from_numpy(np.random.randn(1, G.z_dim)).to(device)
        output = G(image, mask, z, label, truncation_psi=truncation_psi, noise_mode=noise_mode)
        output = (output.permute(0, 2, 3, 1) * 127.5 + 127.5).round().clamp(0, 255).to(torch.uint8)
        output = output[0].cpu().numpy()
        output_image = PIL.Image.fromarray(output, 'RGB')
        visualize_results(image_o,vis_mask,output_image,f'results ')


#----------------------------------------------------------------------------
